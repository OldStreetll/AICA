using Markdig;
using Microsoft.VisualStudio.Shell;
using System;
using System.Collections.Generic;
using System.Text;
using System.Threading;
using System.Threading.Tasks;
using System.Windows;
using System.Windows.Controls;
using System.Windows.Input;
using AICA.Options;
using AICA.Core.LLM;
using AICA.Core.Agent;
using AICA.Core.Tools;
using AICA.Core.Storage;
using AICA.Agent;
using EnvDTE80;

namespace AICA.ToolWindows
{
    public partial class ChatToolWindowControl : UserControl
    {
        private readonly MarkdownPipeline _markdownPipeline;
        private readonly List<ConversationMessage> _conversation = new List<ConversationMessage>();
        private readonly List<ChatMessage> _llmHistory = new List<ChatMessage>();
        private bool _isBrowserReady;
        private bool _isSending;
        private OpenAIClient _llmClient;
        private CancellationTokenSource _currentCts;
        private bool _agentMode = true; // Default to Agent mode
        private AgentExecutor _agentExecutor;
        private ToolDispatcher _toolDispatcher;
        private VSAgentContext _agentContext;
        private VSUIContext _uiContext;
        private readonly ConversationStorage _conversationStorage = new ConversationStorage();
        private string _currentConversationId;

        public ChatToolWindowControl()
        {
            InitializeComponent();

            _markdownPipeline = new MarkdownPipelineBuilder()
                .UseAdvancedExtensions()
                .Build();

            ChatBrowser.LoadCompleted += ChatBrowser_LoadCompleted;
            ChatBrowser.NavigateToString(BuildPageHtml(string.Empty));

            Loaded += ChatToolWindowControl_Loaded;
        }

        private void ChatToolWindowControl_Loaded(object sender, RoutedEventArgs e)
        {
            // Run path mismatch check on load (independent of agent initialization)
            try
            {
                ThreadHelper.JoinableTaskFactory.Run(async () =>
                {
                    await ThreadHelper.JoinableTaskFactory.SwitchToMainThreadAsync();
                    var dte = await AsyncServiceProvider.GlobalProvider.GetServiceAsync(typeof(EnvDTE.DTE)) as DTE2;
                    if (dte?.Solution == null || string.IsNullOrEmpty(dte.Solution.FullName))
                        return;

                    var slnDir = System.IO.Path.GetDirectoryName(dte.Solution.FullName);
                    var cmakeCachePath = System.IO.Path.Combine(slnDir, "CMakeCache.txt");
                    if (!System.IO.File.Exists(cmakeCachePath))
                        return;

                    string cmakeHomeDir = null;
                    using (var reader = new System.IO.StreamReader(cmakeCachePath))
                    {
                        string line;
                        while ((line = reader.ReadLine()) != null)
                        {
                            if (line.StartsWith("CMAKE_HOME_DIRECTORY:INTERNAL=", StringComparison.OrdinalIgnoreCase))
                            {
                                cmakeHomeDir = line.Substring("CMAKE_HOME_DIRECTORY:INTERNAL=".Length).Trim();
                                cmakeHomeDir = cmakeHomeDir.Replace('/', '\\');
                                break;
                            }
                        }
                    }

                    if (string.IsNullOrEmpty(cmakeHomeDir))
                        return;

                    var workingParent = System.IO.Path.GetDirectoryName(slnDir.TrimEnd('\\', '/'));
                    var cmakeParent = System.IO.Path.GetDirectoryName(cmakeHomeDir.TrimEnd('\\', '/'));

                    bool isUnderSameRoot = false;
                    if (!string.IsNullOrEmpty(workingParent) && !string.IsNullOrEmpty(cmakeParent))
                    {
                        var wpNorm = workingParent.TrimEnd('\\', '/') + "\\";
                        var cpNorm = cmakeParent.TrimEnd('\\', '/') + "\\";
                        isUnderSameRoot =
                            wpNorm.Equals(cpNorm, StringComparison.OrdinalIgnoreCase) ||
                            cmakeHomeDir.StartsWith(wpNorm, StringComparison.OrdinalIgnoreCase) ||
                            slnDir.StartsWith(cpNorm, StringComparison.OrdinalIgnoreCase);
                    }

                    if (!isUnderSameRoot)
                    {
                        WarningText.Text =
                            $"\u5f53\u524d\u9879\u76ee\u4e0d\u5728\u539f\u59cb\u7f16\u8bd1\u76ee\u5f55\u4e2d\u6253\u5f00\uff1a\n" +
                            $"\u539f\u59cb\u6e90\u7801\u76ee\u5f55: {cmakeHomeDir}\n" +
                            $"\u5f53\u524d\u5de5\u4f5c\u76ee\u5f55: {slnDir}\n\n" +
                            $"AICA \u53ef\u80fd\u65e0\u6cd5\u6b63\u786e\u89e3\u6790\u6e90\u7801\u6587\u4ef6\u8def\u5f84\u3002\n" +
                            $"\u8bf7\u5728\u539f\u59cb\u7f16\u8bd1\u76ee\u5f55\u4e2d\u6253\u5f00\u89e3\u51b3\u65b9\u6848\uff0c\u6216\u91cd\u65b0\u8fd0\u884c CMake \u751f\u6210\u4ee5\u66f4\u65b0\u8def\u5f84\u3002";
                        WarningBanner.Visibility = Visibility.Visible;
                    }
                });
            }
            catch (Exception ex)
            {
                System.Diagnostics.Debug.WriteLine($"[AICA] Path mismatch check on load failed: {ex.Message}");
            }
        }

        private void ChatBrowser_LoadCompleted(object sender, System.Windows.Navigation.NavigationEventArgs e)
        {
            _isBrowserReady = true;
        }

        public void UpdateContent(string content)
        {
            var html = Markdig.Markdown.ToHtml(content ?? string.Empty, _markdownPipeline);
            UpdateBrowserContent($"<div class=\"message assistant\"><div class=\"role\">AI</div><div class=\"content\">{html}</div></div>");
        }

        public void AppendMessage(string role, string content)
        {
            _conversation.Add(new ConversationMessage { Role = role, Content = content });
            RenderConversation();
        }

        /// <summary>
        /// Send a message programmatically (from right-click commands) and trigger LLM response
        /// </summary>
        public async System.Threading.Tasks.Task SendProgrammaticMessageAsync(string userMessage)
        {
            if (_isSending || string.IsNullOrWhiteSpace(userMessage)) return;

            await ThreadHelper.JoinableTaskFactory.SwitchToMainThreadAsync();
            InputTextBox.Text = userMessage;
            await SendMessageAsync();
        }

        public void ClearConversation()
        {
            _conversation.Clear();
            _llmHistory.Clear();
            _llmClient?.Dispose();
            _llmClient = null;
            _agentExecutor = null;
            _toolDispatcher = null;
            _agentContext = null;
            _uiContext = null;
            WarningBanner.Visibility = Visibility.Collapsed;
            _currentConversationId = null;
            UpdateBrowserContent(string.Empty);
        }

        private void InitializeAgentComponents(GeneralOptions options)
        {
            // Initialize tool dispatcher with available tools
            _toolDispatcher = new ToolDispatcher();
            _toolDispatcher.RegisterTool(new ReadFileTool());
            _toolDispatcher.RegisterTool(new WriteFileTool());
            _toolDispatcher.RegisterTool(new EditFileTool());
            _toolDispatcher.RegisterTool(new ListDirTool());
            _toolDispatcher.RegisterTool(new GrepSearchTool());
            _toolDispatcher.RegisterTool(new FindByNameTool());
            _toolDispatcher.RegisterTool(new RunCommandTool());
            _toolDispatcher.RegisterTool(new UpdatePlanTool());
            _toolDispatcher.RegisterTool(new AttemptCompletionTool());
            _toolDispatcher.RegisterTool(new CondenseTool());
            _toolDispatcher.RegisterTool(new ListCodeDefinitionsTool());

            // Initialize LLM client
            var clientOptions = new LLMClientOptions
            {
                ApiEndpoint = options.ApiEndpoint,
                ApiKey = options.ApiKey,
                Model = options.ModelName,
                MaxTokens = options.MaxTokens,
                Temperature = options.Temperature,
                TimeoutSeconds = options.RequestTimeoutSeconds,
                Stream = true
            };
            _llmClient = new OpenAIClient(clientOptions);

            // Initialize VS-specific contexts
            ThreadHelper.JoinableTaskFactory.Run(async () =>
            {
                await ThreadHelper.JoinableTaskFactory.SwitchToMainThreadAsync();
                var dte = await AsyncServiceProvider.GlobalProvider.GetServiceAsync(typeof(EnvDTE.DTE)) as DTE2;
                
                _agentContext = new VSAgentContext(
                    dte,
                    confirmationHandler: async (op, details, ct) =>
                    {
                        return await _uiContext.ShowConfirmationAsync(op, details, ct);
                    });

                // Check for path mismatch warning (project opened from non-original location)
                if (!string.IsNullOrEmpty(_agentContext.PathMismatchWarning))
                {
                    WarningText.Text = _agentContext.PathMismatchWarning;
                    WarningBanner.Visibility = Visibility.Visible;
                }

                _uiContext = new VSUIContext(
                    streamingContentUpdater: content =>
                    {
                        ThreadHelper.JoinableTaskFactory.Run(async () =>
                        {
                            await ThreadHelper.JoinableTaskFactory.SwitchToMainThreadAsync();
                            RenderConversation(content);
                        });
                    });
            });

            // Initialize Agent executor with custom instructions and token budget from options
            // Token budget: maxTokens * 8 gives rough context window size (response tokens vs context tokens)
            int tokenBudget = Math.Max(8000, options.MaxTokens * 8);
            _agentExecutor = new AgentExecutor(
                _llmClient,
                _toolDispatcher,
                maxIterations: options.MaxAgentIterations,
                maxTokenBudget: tokenBudget,
                customInstructions: options.CustomInstructions);
        }

        private void RenderConversation(string streamingContent = null)
        {
            var bodyBuilder = new StringBuilder();
            
            foreach (var message in _conversation)
            {
                var roleClass = message.Role == "user" ? "user" : "assistant";
                var roleName = message.Role == "user" ? "You" : "AI";
                var html = Markdig.Markdown.ToHtml(message.Content ?? string.Empty, _markdownPipeline);
                bodyBuilder.AppendLine($"<div class=\"message {roleClass}\"><div class=\"role\">{roleName}</div><div class=\"content\">{html}</div></div>");
            }

            if (!string.IsNullOrEmpty(streamingContent))
            {
                var streamingHtml = Markdig.Markdown.ToHtml(streamingContent, _markdownPipeline);
                bodyBuilder.AppendLine($"<div class=\"message assistant streaming\"><div class=\"role\">AI</div><div class=\"content\">{streamingHtml}</div></div>");
            }

            UpdateBrowserContent(bodyBuilder.ToString());
        }

        private void UpdateBrowserContent(string innerHtml)
        {
            if (!_isBrowserReady || ChatBrowser.Document == null)
            {
                ChatBrowser.NavigateToString(BuildPageHtml(innerHtml));
                return;
            }

            try
            {
                dynamic doc = ChatBrowser.Document;
                dynamic log = doc?.getElementById("chat-log");
                if (log != null)
                {
                    log.innerHTML = innerHtml;
                    dynamic window = doc?.parentWindow;
                    window?.scrollTo(0, doc?.body?.scrollHeight ?? 0);
                    return;
                }
            }
            catch { }

            ChatBrowser.NavigateToString(BuildPageHtml(innerHtml));
        }

        private async void SendButton_Click(object sender, RoutedEventArgs e)
        {
            await SendMessageAsync();
        }

        private async void InputTextBox_KeyDown(object sender, KeyEventArgs e)
        {
            if (e.Key == Key.Enter && Keyboard.Modifiers == ModifierKeys.None)
            {
                e.Handled = true;
                await SendMessageAsync();
            }
        }

        private async System.Threading.Tasks.Task SendMessageAsync()
        {
            var userMessage = InputTextBox.Text.Trim();
            if (string.IsNullOrWhiteSpace(userMessage)) return;

            if (_isSending) return;

            _isSending = true;
            InputTextBox.IsEnabled = false;
            SendButton.IsEnabled = false;
            _currentCts = new CancellationTokenSource();

            try
            {
                InputTextBox.Text = string.Empty;
                AppendMessage("user", userMessage);

                var options = await GeneralOptions.GetLiveInstanceAsync();
                
                if (string.IsNullOrEmpty(options.ApiEndpoint))
                {
                    AppendMessage("assistant", "‚ö†Ô∏è Please configure the LLM API endpoint in Tools > Options > AICA > General");
                    return;
                }

                // Initialize components if needed
                if (_llmClient == null)
                {
                    InitializeAgentComponents(options);
                }

                // Use Agent mode only if tool calling is enabled
                if (_agentMode && _agentExecutor != null && options.EnableToolCalling)
                {
                    await ExecuteAgentModeAsync(userMessage);
                }
                else
                {
                    await ExecuteChatModeAsync(userMessage);
                }

                // Auto-save conversation after each exchange
                await SaveConversationAsync();
            }
            catch (OperationCanceledException)
            {
                AppendMessage("assistant", "üõë Request cancelled.");
            }
            catch (LLMException ex)
            {
                AppendMessage("assistant", $"‚ùå LLM Error: {ex.Message}");
            }
            catch (Exception ex)
            {
                AppendMessage("assistant", $"‚ùå Error: {ex.Message}");
            }
            finally
            {
                _isSending = false;
                _currentCts?.Dispose();
                _currentCts = null;
                await ThreadHelper.JoinableTaskFactory.SwitchToMainThreadAsync();
                InputTextBox.IsEnabled = true;
                SendButton.IsEnabled = true;
                InputTextBox.Focus();
            }
        }

        private async System.Threading.Tasks.Task ExecuteAgentModeAsync(string userMessage)
        {
            var responseBuilder = new StringBuilder();
            var toolOutputBuilder = new StringBuilder();
            var hasToolCalls = false;

            // Show immediate feedback while waiting for LLM's first token (TTFT)
            RenderConversation("üí≠ *ÊÄùËÄÉ‰∏≠...*");

            // Capture the WPF dispatcher so we can marshal UI updates from background thread
            var dispatcher = this.Dispatcher;

            // Run the entire agent loop on a background thread to prevent UI deadlocks.
            // The IAsyncEnumerable pattern causes MoveNextAsync() to resume the generator
            // on the caller's thread. If the caller is the UI thread, all awaits in the
            // generator chain (AgentExecutor -> OpenAIClient -> HttpClient) capture the UI
            // sync context, causing deadlocks when tool execution tries to post back.
            await System.Threading.Tasks.Task.Run(async () =>
            {
                await foreach (var step in _agentExecutor.ExecuteAsync(userMessage, _agentContext, _uiContext, _currentCts.Token))
                {
                    // Marshal UI updates to the UI thread via Dispatcher.Invoke.
                    // This blocks the background thread until the UI processes the update,
                    // ensuring sequential rendering. The UI thread is free (awaiting Task.Run).
                    dispatcher.Invoke(new Action(() =>
                    {
                        switch (step.Type)
                        {
                            case AgentStepType.TextChunk:
                                responseBuilder.Append(step.Text);
                                // Always show streaming text in real-time.
                                // For tool-using responses, pre-tool text is discarded
                                // when the first ToolStart arrives (see below).
                                // For non-tool responses (knowledge questions, explanations),
                                // the streaming text IS the actual answer.
                                RenderConversation(responseBuilder.ToString() + toolOutputBuilder.ToString());
                                break;

                            case AgentStepType.ToolStart:
                                // When first tool arrives: discard any buffered pre-tool text
                                if (!hasToolCalls)
                                {
                                    if (responseBuilder.Length > 100)
                                    {
                                        System.Diagnostics.Debug.WriteLine($"[AICA-UI] Discarding {responseBuilder.Length} chars of pre-tool text");
                                    }
                                    responseBuilder.Clear();
                                }
                                hasToolCalls = true;
                                // Don't show attempt_completion in tool logs (its text becomes the main response)
                                if (step.ToolCall.Name != "attempt_completion")
                                {
                                    toolOutputBuilder.AppendLine();
                                    toolOutputBuilder.AppendLine($"üîß **Calling tool:** `{step.ToolCall.Name}`");
                                }
                                RenderConversation(responseBuilder.ToString() + toolOutputBuilder.ToString());
                                break;

                            case AgentStepType.ToolResult:
                                // Skip attempt_completion results in tool log (shown as main response)
                                if (step.ToolCall?.Name == "attempt_completion")
                                {
                                    break;
                                }
                                var status = step.Result.Success ? "‚úÖ" : "‚ùå";
                                var resultPreview = TruncateForDisplay(step.Result.Success ? step.Result.Content : step.Result.Error, 1000);
                                toolOutputBuilder.AppendLine($"{status} **Result:** {resultPreview}");
                                toolOutputBuilder.AppendLine();
                                RenderConversation(responseBuilder.ToString() + toolOutputBuilder.ToString());
                                break;

                            case AgentStepType.Complete:
                                // Build final content: for tool-assisted responses, include
                                // the detailed text the LLM generated after seeing tool results.
                                string finalContent;
                                if (hasToolCalls)
                                {
                                    // Prefer responseBuilder (detailed LLM text from post-tool iterations)
                                    // over step.Text (brief attempt_completion summary).
                                    var mainText = responseBuilder.ToString().Trim();
                                    var completionText = step.Text?.Trim() ?? "";

                                    string textContent;
                                    if (!string.IsNullOrEmpty(mainText))
                                    {
                                        // Use the detailed streaming text the user saw during generation
                                        textContent = mainText;
                                    }
                                    else if (!string.IsNullOrEmpty(completionText))
                                    {
                                        // Fallback to attempt_completion summary
                                        textContent = completionText;
                                    }
                                    else
                                    {
                                        textContent = "";
                                    }

                                    finalContent = (!string.IsNullOrEmpty(textContent) ? textContent + "\n" : "")
                                        + toolOutputBuilder.ToString();
                                }
                                else
                                {
                                    finalContent = responseBuilder.ToString() + toolOutputBuilder.ToString();
                                }

                                // Diagnostic hint: only if no tools AND response has action-like language
                                // AND response is substantial (>200 chars to avoid false positives on greetings)
                                if (!hasToolCalls && responseBuilder.Length > 200 && ContainsToolIntentLanguage(responseBuilder.ToString()))
                                {
                                    finalContent += "\n\n---\n‚ö†Ô∏è **ÊèêÁ§∫**: AI ÊèèËø∞‰∫ÜË¶ÅÊâßË°åÁöÑÊìç‰Ωú‰ΩÜÊú™ÂÆûÈôÖË∞ÉÁî®Â∑•ÂÖ∑„ÄÇ\n" +
                                        "ÂèØËÉΩÂéüÂõ†Ôºö\n" +
                                        "1. LLM ÊúçÂä°Âô®Êú™ÂêØÁî® function callingÔºàÈúÄË¶Å `--enable-auto-tool-choice`Ôºâ\n" +
                                        "2. Ê®°Âûã‰∏çÊîØÊåÅ OpenAI Ê†ºÂºèÁöÑÂ∑•ÂÖ∑Ë∞ÉÁî®\n" +
                                        "3. Âú®ÈÄâÈ°π‰∏≠Ê£ÄÊü• 'Enable Tool Calling' ÊòØÂê¶Â∑≤ÂêØÁî®";
                                }

                                if (!string.IsNullOrWhiteSpace(finalContent))
                                {
                                    _conversation.Add(new ConversationMessage { Role = "assistant", Content = finalContent });
                                }
                                RenderConversation();
                                break;

                            case AgentStepType.Error:
                                AppendMessage("assistant", $"‚ùå Agent Error: {step.ErrorMessage}");
                                break;
                        }
                    }));
                }
            });
        }

        private async System.Threading.Tasks.Task ExecuteChatModeAsync(string userMessage)
        {
            // Add system prompt if this is the first message
            if (_llmHistory.Count == 0)
            {
                _llmHistory.Add(ChatMessage.System(
                    "You are AICA, an AI coding assistant for Visual Studio. " +
                    "Help the user with programming tasks, code explanations, debugging, and more. " +
                    "Be concise but thorough. Use markdown for code formatting."));
            }

            _llmHistory.Add(ChatMessage.User(userMessage));

            var responseBuilder = new StringBuilder();
            var dispatcher = this.Dispatcher;

            // Show immediate feedback while waiting for LLM's first token (TTFT)
            RenderConversation("üí≠ *ÊÄùËÄÉ‰∏≠...*");

            // Run LLM streaming on background thread, dispatch UI updates via Dispatcher.Invoke
            await System.Threading.Tasks.Task.Run(async () =>
            {
                await foreach (var chunk in _llmClient.StreamChatAsync(_llmHistory, null, _currentCts.Token))
                {
                    if (chunk.Type == LLMChunkType.Text && !string.IsNullOrEmpty(chunk.Text))
                    {
                        responseBuilder.Append(chunk.Text);
                        var content = responseBuilder.ToString();
                        dispatcher.Invoke(new Action(() => RenderConversation(content)));
                    }
                    else if (chunk.Type == LLMChunkType.Done)
                    {
                        break;
                    }
                }
            });

            var finalResponse = responseBuilder.ToString();
            if (!string.IsNullOrEmpty(finalResponse))
            {
                _llmHistory.Add(ChatMessage.Assistant(finalResponse));
                _conversation.Add(new ConversationMessage { Role = "assistant", Content = finalResponse });
                await ThreadHelper.JoinableTaskFactory.SwitchToMainThreadAsync();
                RenderConversation();
            }
            else
            {
                AppendMessage("assistant", "‚ö†Ô∏è No response received from the LLM.");
            }
        }

        private string TruncateForDisplay(string text, int maxLength)
        {
            if (string.IsNullOrEmpty(text)) return "(empty)";
            if (text.Length <= maxLength) return text.Replace("\n", " ").Replace("\r", "");
            return text.Substring(0, maxLength).Replace("\n", " ").Replace("\r", "") + "...";
        }

        private bool ContainsToolIntentLanguage(string text)
        {
            if (string.IsNullOrEmpty(text)) return false;
            
            // Detect phrases that indicate the AI intended to use tools but didn't
            var intentPhrases = new[]
            {
                "ËÆ©Êàë", "ÊàëÂ∞Ü", "ÊàëÊù•", "Êàë‰ºö", "ËÆ©Êàë‰ª¨",
                "Êü•Áúã", "ËØªÂèñ", "ÂàóÂá∫", "ÊâìÂºÄ", "Ê£ÄÊü•",
                "let me", "i will", "i'll", "let's",
                "read the file", "list the", "check the"
            };
            
            var lowerText = text.ToLowerInvariant();
            foreach (var phrase in intentPhrases)
            {
                if (lowerText.Contains(phrase.ToLowerInvariant()))
                    return true;
            }
            return false;
        }

        private async System.Threading.Tasks.Task SaveConversationAsync()
        {
            try
            {
                if (_conversation.Count == 0) return;

                var record = new ConversationRecord
                {
                    Id = _currentConversationId ?? Guid.NewGuid().ToString("N"),
                    WorkingDirectory = _agentContext?.WorkingDirectory,
                    Messages = new List<ConversationMessageRecord>()
                };

                // Set title from first user message
                foreach (var msg in _conversation)
                {
                    if (msg.Role == "user" && string.IsNullOrEmpty(record.Title))
                    {
                        record.Title = msg.Content.Length > 50
                            ? msg.Content.Substring(0, 47) + "..."
                            : msg.Content;
                    }

                    record.Messages.Add(new ConversationMessageRecord
                    {
                        Role = msg.Role,
                        Content = msg.Content
                    });
                }

                if (_currentConversationId == null)
                {
                    _currentConversationId = record.Id;
                    record.CreatedAt = DateTimeOffset.UtcNow;
                }

                await _conversationStorage.SaveConversationAsync(record);

                // Periodic cleanup
                if (_conversation.Count % 20 == 0)
                    await _conversationStorage.CleanupOldConversationsAsync(100);
            }
            catch (Exception ex)
            {
                System.Diagnostics.Debug.WriteLine($"[AICA] Failed to save conversation: {ex.Message}");
            }
        }

        private void ClearButton_Click(object sender, RoutedEventArgs e)
        {
            ClearConversation();
        }

        private void SettingsButton_Click(object sender, RoutedEventArgs e)
        {
            VS.Commands.ExecuteAsync("Tools.Options").FireAndForget();
        }

        private string BuildPageHtml(string innerContent)
        {
            return $@"<!DOCTYPE html>
<html>
<head>
    <meta charset=""utf-8"" />
    <style>
        :root {{ color-scheme: light dark; }}
        body {{
            margin: 0; padding: 0;
            font-family: 'Segoe UI', 'Helvetica Neue', Arial, sans-serif;
            font-size: 14px; line-height: 1.5;
            background: #1e1e1e; color: #d4d4d4;
        }}
        .container {{ padding: 12px 16px 20px 16px; max-width: 1100px; margin: 0 auto; }}
        @media (prefers-color-scheme: light) {{
            body {{ background: #ffffff; color: #1e1e1e; }}
            pre code {{ background: #f6f8fa; color: #1e1e1e; }}
            .message {{ background: #f5f7fb; border-color: #d0d7de; }}
            .message.user {{ background: #e8f1ff; border-color: #b7cff9; }}
        }}
        .message {{
            margin: 0 0 12px 0; padding: 10px 12px;
            border-radius: 8px; border: 1px solid #3c3c3c;
            background: #252526; box-shadow: 0 1px 2px rgba(0,0,0,0.35);
        }}
        .message.user {{ background: #0e3a5c; border-color: #2d5f8a; }}
        .message.streaming {{ opacity: 0.85; }}
        .role {{
            font-size: 11px; letter-spacing: 0.03em;
            text-transform: uppercase; color: #9ca3af; margin-bottom: 6px;
        }}
        .content p {{ margin: 0 0 0.75em 0; }}
        pre {{ overflow-x: auto; }}
        pre code {{
            display: block; padding: 12px; border-radius: 6px;
            background: #1e1e1e; color: #d4d4d4;
            font-family: Consolas, 'Courier New', monospace; font-size: 13px;
        }}
        code {{
            font-family: Consolas, 'Courier New', monospace;
            background: rgba(255,255,255,0.08); padding: 0 3px; border-radius: 3px;
        }}
        a {{ color: #4aa3ff; text-decoration: none; }}
        a:hover {{ text-decoration: underline; }}
        h1, h2, h3, h4, h5, h6 {{ margin-top: 1.4em; margin-bottom: 0.6em; }}
    </style>
</head>
<body>
<div id=""chat-log"" class=""container"">
{innerContent}
</div>
</body>
</html>";
        }

        private class ConversationMessage
        {
            public string Role { get; set; }
            public string Content { get; set; }
        }
    }
}
